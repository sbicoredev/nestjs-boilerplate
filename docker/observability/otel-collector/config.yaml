receivers:
  otlp:
    protocols:
      http:
        endpoint: 0.0.0.0:4318
        include_metadata: true
        cors:
          allowed_origins:
            - http://*

processors:
  batch:
    timeout: 5s                # Max time before sending a batch (default: 200ms)
    send_batch_size: 1024      # Target number of items per batch (default: 8192)
    send_batch_max_size: 2048  # Max upper limit for a batch size (default: 0, disabled)
  memory_limiter:
    check_interval: 5s
    limit_mib: 512
    spike_limit_mib: 128
  tail_sampling:
    decision_wait: 30s # The time to wait for a decision to be made.
    policies: [
        {
          name: sample-erroring-traces,
          type: status_code,
          status_code: { status_codes: [ERROR] },
        },
        {
          name: sample-long-traces,
          type: latency,
          latency: { threshold_ms: 200 },
        },
      ]

extensions:
  health_check:
    endpoint: 0.0.0.0:13133
#   pprof:
#     endpoint: 0.0.0.0:1777
#   zpages:
#     endpoint: 0.0.0.0:55679

exporters:
  debug:
    verbosity: detailed
  otlphttp/logs:
    endpoint: http://loki:3100/otlp
    tls:
      insecure: true
  otlphttp/metrics:
    endpoint: http://prometheus:9090/api/v1/otlp
    tls:
      insecure: true
  otlphttp/traces:
    endpoint: http://tempo:4318
    tls:
      insecure: true
  # otlphttp/profiles:
  #   endpoint: http://pyroscope:4040
  #   tls:
  #     insecure: true

service:
  extensions: [health_check]
  pipelines:
    logs:
      receivers: [otlp]
      processors: [batch]
      exporters: [otlphttp/logs]
    metrics:
      receivers: [otlp]
      processors: [batch]
      exporters: [otlphttp/metrics]
    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [otlphttp/traces]
    # profiles:
    #   receivers: [otlp]
    #   exporters: [debug, otlphttp/profiles]
